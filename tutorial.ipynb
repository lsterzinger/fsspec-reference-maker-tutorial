{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "offensive-tuner",
   "metadata": {},
   "source": [
    "# `fsspec-reference-maker` tutorial\n",
    "\n",
    "Created June 8th, 2020 by [Lucas Sterzinger](mailto:lsterzinger@ucdavis.edu) ([Twitter](https://twitter.com/lucassterzinger)) as part of the NCAR [Summer Internship in Parallel Computational Science (SIParCS)](https://www2.cisl.ucar.edu/siparcs)\n",
    "\n",
    "If any part of this tutorial is now out of date, please feel free to open a pull request with a fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsspec_reference_maker.hdf import SingleHdf5ToZarr \n",
    "from fsspec_reference_maker.combine import MultiZarrToZarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-trunk",
   "metadata": {},
   "source": [
    "## Create metadata JSONs\n",
    "\n",
    "### This function returns a list of S3 files for a given satellite, year, and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import s3fs\n",
    "import datetime as dt\n",
    "import zipfile\n",
    "import logging\n",
    "import fsspec\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(sat,lyr,idyjl):\n",
    "    # arguments\n",
    "    # sat   goes-east,goes-west,himawari\n",
    "    # lyr   year\n",
    "    # idyjl day of year\n",
    "    \n",
    "    d = dt.datetime(lyr,1,1) + dt.timedelta(days=idyjl)\n",
    "    fs = s3fs.S3FileSystem(anon=True) #connect to s3 bucket!\n",
    "\n",
    "    #create strings for the year and julian day\n",
    "    imon,idym=d.month,d.day\n",
    "    syr,sjdy,smon,sdym = str(lyr).zfill(4),str(idyjl).zfill(3),str(imon).zfill(2),str(idym).zfill(2)\n",
    "    \n",
    "    #use glob to list all the files in the directory\n",
    "    if sat=='goes-east':\n",
    "        file_location,var = fs.glob('s3://noaa-goes16/ABI-L2-SSTF/'+syr+'/'+sjdy+'/*/*.nc'),'SST'\n",
    "    if sat=='goes-west':\n",
    "        file_location,var = fs.glob('s3://noaa-goes17/ABI-L2-SSTF/'+syr+'/'+sjdy+'/*/*.nc'),'SST'\n",
    "    \n",
    "    return file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = get_file_list(\"goes-east\", 2020, 210)\n",
    "urls = [\"s3://\" + f for f in flist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-anger",
   "metadata": {},
   "source": [
    "### This function creates JSON metadata files for each of the S3 files in the local `jsons/` directory\n",
    "\n",
    "These files point to the S3 location of the netCDF files, and only need to be created once. Tihs process took me about 10 minutes to generate the JSONs for 24 files. This function could easily be made to run in parallel for faster performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_json(urllist):\n",
    "    so = dict(\n",
    "        mode=\"rb\", anon=True, default_fill_cache=False, default_cache_type=\"none\"\n",
    "    )\n",
    "    zf = zipfile.ZipFile(\"out.zip\", mode=\"w\")\n",
    "    for u in tqdm(urllist):\n",
    "        with fsspec.open(u, **so) as inf:\n",
    "            h5chunks = SingleHdf5ToZarr(inf, u, xarray=True, inline_threshold=100)\n",
    "            with zf.open(os.path.basename(u) + \".json\", 'w') as outf:\n",
    "                outf.write(json.dumps(h5chunks.translate()).encode())\n",
    "\n",
    "    # for u in tqdm(urllist):\n",
    "    #     with fsspec.open(u, **so) as f:\n",
    "    #         h5chunks = fsshdf.SingleHdf5ToZarr(f, u, xarray=True)\n",
    "    #         j = h5chunks.translate()\n",
    "    #         fname = u.split(\"/\")[7]\n",
    "    #         with open(f\"./jsons/{fname}.json\", \"w\") as fout:\n",
    "    #             fout.write(json.dumps(j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_json(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-blake",
   "metadata": {},
   "source": [
    "***\n",
    "## Read remote netCDF files with xarray and fsspec\n",
    "\n",
    "### First, create a list of JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = sorted(glob(\"./jsons/*.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-atlantic",
   "metadata": {},
   "source": [
    "### Then, loop over the files and use `fsspec.get_mapper()` to create mappers for each file object, creating a list of mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "mzz = MultiZarrToZarr(\n",
    "    # \"./jsons/*.json\",\n",
    "    \"zip://*.json::out.zip\",\n",
    "    remote_protocol=\"s3\",\n",
    "    remote_options={'anon':True},\n",
    "    xarray_kwargs={\n",
    "        \"decode_cf\" : False,\n",
    "        \"mask_and_scale\" : False,\n",
    "        \"decode_times\" : False,\n",
    "        \"decode_timedelta\" : False,\n",
    "        \"use_cftime\" : False,\n",
    "        \"decode_coords\" : False\n",
    "    },\n",
    "    with_mf='t'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mzz.translate(\"combined.json\")"
   ]
  },
  {
   "source": [
    "%%time\n",
    "fs = fsspec.filesystem(\"reference\", fo=\"./combined.json\", remote_protocol=\"s3\", \n",
    "                        remote_options={\"anon\":True}, skip_instance_cache=True)\n",
    "m = fs.get_mapper(\"\")\n",
    "ds = xr.open_dataset(m, engine='zarr')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.SST.where(ds.DQF==0).isel(t=0).hvplot.image(x='x', y='y', rasterize=True, aspect='equal', cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-tonight",
   "metadata": {},
   "source": [
    "### Take a subset of the data (in this case, the Gulf Stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-summit",
   "metadata": {},
   "source": [
    "### Select a single time with `.isel(t=14)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "subset = ds.sel(x=slice(-0.01,0.07215601),y=slice(0.12,0.09))  #reduce to GS region\n",
    "\n",
    "masked = subset.SST.where(subset.DQF==0)\n",
    "\n",
    "masked.isel(t=14).plot(vmin=14+273.15,vmax=30+273.15,cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-survival",
   "metadata": {},
   "source": [
    "### Plot a mean along the time axis (1-day average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "subset = ds.sel(x=slice(-0.01,0.07215601),y=slice(0.12,0.09))  #reduce to GS region\n",
    "\n",
    "masked = subset.SST.where(subset.DQF==0)\n",
    "\n",
    "masked.mean(\"t\", skipna=True).plot(vmin=14+273.15,vmax=30+273.15,cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-florence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('fsspec-tutorial': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "interpreter": {
   "hash": "3bd1516611ce5bb0d255a0db4dd9a6f38a599d9a5d246e2fe5677e0b16b804b8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}